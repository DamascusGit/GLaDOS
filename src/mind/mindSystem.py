#|%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#|					 	TOP OF FILE:	 mind/mindSystem.py
#|------------------------------------------------------------------------------
#|	The below module documentation string will be displayed by pydoc3.
#|vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
"""
"""
#|^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
#|	End of module documentation string.
#|------------------------------------------------------------------------------


# Stuff to put in the 'mind' package (in this file mindSystem.py, for now)
#
# Classes to be defined here (or that, at least, are used here):
#
#
#		Action_ (imported from supervisor.action module) -
#
#			Encapsulates an action taken by the AI, or a human user.
#			The difference between an action and an event is that an
#			action is an 'active' entity; it can and generally will 
#			be processed by TheActionProcessor_, possibly causing 
#			GLaDOS commands to be executed, which can have impacts on
#			other GLaDOS subsystems, and in the real world as well.  
#			In contrast, an Event is just a static record of a past
#			action.  Events can also be records of actions taken by
#			the system itself (such as a system shutdown).
#
#
#		The_AI_Cognosphere_Channel -
#
#			This is an ActionChannel_ that broadcasts all of the 'actions'
#			that are supposed to be perceptible within the AI's "Cognosphere"
#			or cognitive sphere, i.e., its overall field of awareness.  Right 
#			now, this includes:
#
#				* Actions that are generated by the AI itself (i.e., its 
#					speech acts, including command lines).
#
#				* Actions generated by the rest of the system that are 
#					above a certain threshold level of 'importance.'
#
#			At present, the Cognosphere channel reports on actions whenever 
#			they are conceived, initiated, executing or completed.
#
#
#		AI_ActionSubscriber -
#
#			This subclass of supervisor.action.ActionSubscriber_ takes
#			care of subscribing to notifications from the system about
#			various actions that are of interest to us.  Presently, the
#			subscriber just watches everything that's broadcast on the 
#			"AI Cognosphere Channel" and pays attention to the following
#			types of updates:
#
#				* Initiation of an AI action. (Note these are just
#					our own actions, but we get notified about them.)
#
#				* Execution of a sufficiently high-importance action
#					by the system itself.
#			
#		
#
#
#		
#
#		CognitiveStream - 
#
#			The "cognitive stream" is a singleton object that manages the 
#			indefinite-length, ever-growing sequence of "cognitive events," 
#			such as thoughts and perceptions, associated with the AI's ongoing 
#			processing.  Events themselves are defined in the 'events' package,
#			but in general they can include:
#
#				* Blocks of text generated by the AI, or by a human user.
#
#				* Snapshots of windows that the AI was looking at.
#
#			Generally speaking, as cognitive events occur, they are appended
#			to the cognitive stream.  Data in the cognitive stream is maintained
#			in two places:  The history buffer (in memory) and a backing store
#			in the filesystem (maintained by the 'memory' package).
#
#			One thing that the A.I. can be enabled to do is to scroll around in 
#			its cognitive stream, so that, instead of always looking at the most
#			recent material, it can scoll back and see what happened earlier.
#			Also, searching back in the cognitive stream is another option.
#
#
#		TheCognitiveProcess -
#
#			A subclass of SubProcess (i.e., a GLaDOS process) in which the
#			process implementing the AI's cognitive framework runs.
#
#
#		TheCognitiveSystem	- 
#
#			Singleton for the entire cognitive system, itself.  This includes
#			features like:
#
#				- A GLaDOS process in which the cognitive system runs.
#					This runs the main loop for cognitive processing.
#					This does the following things:
#
#						1. Wait for an external signal, or internal
#							timeout.
#
#						2. Refresh the receptive field.  (Repaint it,
#							update display for human, send it to the
#							AI's API.)
#
#						3. Receive action back from the AI's API.
#
#						4. Send it to the ActionProcessor.
#
#				- Makes use of the receptive field ('field' package).
#					This is effectively the AI's "computer screen" that
#					it is always looking at.  The mind system takes 
#					images of the receptive field at certain points in
#					time, and passes them to the underlying AI's API 
#					for processing.  The AI's predicted continuation is
#					then taken as its next 'action' and is passed to
#					the ActionProcessor for processing.
#					

from config.configuration import TheAIPersonaConfig
	# This class specifies the configuration of the AI's persona.


#---------------------------------------------------------------------------------------
# The following classes are for various types of actions that could be taken by the AI.


class ActionByAI_(Action_):
	def __init__(thisAiAction, 
			description:str="A generic action was taken by the AI.",
				# REQUIRED. A description string. SUBCLASSES SHOULD OVERRIDE THIS VALUE.
			theAI:AI_Entity_=None,		# The AI entity that conceived of taking this action.
		):
		
		super(ActionBySystem_, thisSystemAction).__init__(description, theAI)


class AI_Speech_Action(ActionByAI_):

	"""Class for actions by the AI that consist of it producing some text output.
		At the moment, all actions taken by the AI start out as this type of action,
		and then other types of actions are derived from them as they are 
		interpreted by the system (in particular, the command interface).
	
		AI_Speech_Action instances get created in the main loop of the cognitive
		system upon receiving a completion from the AI; they are then automatically
		initiated. Credit for their conception goes to the persona (annotated as 
		running on the language model); credit for their initiation goes to the 
		cognitive system (on behalf of the persona); credit for their execution 
		goes to the cognitive system as well I guess.  
		
		For resulting command actions, we can credit conception to the AI, initiation
		to the Supervisor, and execution to whatever subsystem/app implements them.
		They can also link back to the speech action they were derived from.
	"""
		
	def __init__(this,
			aiTextOut:strm=None,		# Text output by the AI.
			theAI:AI_Entity_=None,		# The AI entity that conceived of taking this action.
		):
		
			# Get a string denoting the AI.
		this._aiStr = aiStr = str(theAI)
		
			# Store the AI's output text for later reference.
		this._aiTextOut = aiTextOut
		
			# Compose a description, pretty generic but that's fine for now. 
		description = f"{aiStr} generated the text: [{aiTextOut}]"
			# (Later on, if this speech action ends up getting parsed as a command string,
			# then this action may get transmuted into a command action of some sort.)
			
			# Dispatch to superclass to finish initialization.
		super(AI_Speech_Action, this).__init__(description, theAI)

	# Note to self: Should we go ahead and add AI speech actions to the cognitive stream 
	# immediately upon conception? Or wait until the command (if any) is interpreted?
	# I'm thinking yes, we should go ahead and add them at execution time, and the 
	# command (if any) should be treated as a second action that is consequent on the 
	# first action. Use ".interpretedAs" and ".triggeredBy" members as appropriate.

class CommandByAI_(AI_Speech_Action, CommandAction):
	pass
	


# Consider moving this to the mind package since it depends on configuration
# parameters for the AI persona.
@singleton
class The_AI_Cognosphere_Channel(ActionChannel_):
	"""The action system creates this specific action channel which is for 
		reporting actions that we consider eligible for entering into the
		AI's sphere of awareness.  Such actions include:
		
			(1) All actions that were conceived/initiated by the AI 
				itself.
			
			(2) All actions that were conceived/initiated by a human
				user who has logged into GLaDOS to interact with the AI.
			
			(3) All high-importance system actions, which the AI might
				need to be aware of.  The threshold importance level can
				be configured in the system/AI configuration.
	"""
	def willReport(thisChannel, status:str, action:Action_):
		
			# At present, we report all status updates for actions, including
			# 'conceived', 'initiated', 'executing', and 'completed'.  However,
			# the individual subscriber can choose to ignore most of these.
			
		#if status != 'completed': return False
		
			# Next, see if this is an action by the AI itself.  An easy way
			# to check this is to see if this action is an ActionByAI_. 
			# (Instance of this class, or a subclass derived from it.)  A 
			# more sophisticated way would be to actually look at the entity
			# specified in the ._conceivedBy and/or ._initiatedBy members.
			# However, we'll just use the simple method for now.
			
		isAIAction = isinstance(action, ActionByAI_)
		if isAIAction: 	return True
		
		# FUTURE: Check for actions by human users here (not implemented yet
		# because we haven't implemented the login system).
		
			# Next, check to see if this is a system-initiated action.
			
		isSystemAction = isinstance(action, ActionBySystem_)
		if not isSystemAction:	return False
		
			# Get its importance, and our threshold level.
		
		importance = action._importance
		threshold = TheAIPersonaConfig().sysNotifyThresh
		
		return importance >= threshold
		
	


class TheCognitiveSystem: pass

@singleton
class TheCognitiveSystem:
	#---------------------------------------------------------------------------
	"""
	TheCognitiveSystem							 [mobule public singleton class]
	==================
	
		This singleton class implements the central cognitive framework for 
		AIs hosted by GLaDOS.  The cognitive system incorporates the 
		following singleton entities as sub-objects:
		
			TheReceptiveField -
			
				This is effectively the main 'screen' or 'display' that 
				constitutes the GLaDOS system's input interface to the AI.  
				Various processes within GLaDOS modify what appears on the 
				display, and the AI sees it and responds.
			
			TheCognitiveStream - 
			
				This is effectively the ever-growing, time-ordered record 
				of cognitive events (perceptions, thoughts, actions) that 
				are introduced into the AI's cognitive sphere.  Typically 
				the cognitive stream appears as a scrolling display that 
				dominates the AI's receptive field.  Internally, the 
				cognitive stream is implemented by a combination of the 
				'history' (recent history buffer) and 'memory' (long-term 
				backing store) packages working in concert.
			
			TheCognitiveProcess -
			
				A subclass of SubProcess, this is the GLaDOS process within
				which the main processing loop of the AI actually runs.
	"""
	def __init__(theCognitiveSystem:TheCognitiveSystem):
		#-----------------------------------------------------------------------
		"""
		theCognitiveSystem.__init__()		 [special singleton instance method]
		
			This is the singleton instance initializer for the cognitive 
			system class, TheCognitiveSystem.  It creates the singletons
			of our various subobjects, namely, our receptive field, our
			cognitive stream, and our main cognitive process.
		"""
		#vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
	
		_logger.normal("The AI's cognitive system is booting up...")
	
		#|-------------------------------------------------------------------
		#| Step 1:  Create (the input interface to) our AI's receptive field.
		#|vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
	
			# Fetch the configuration of the AI's persona from the config package.
			
		aiConfig = TheAIPersonaConfig()
		
			# Look up its .maxVisibleTokens parameter, which we'll need to know in 
			# order to create our receptive field system--since it determines how 
			# large our receptive field will be.
			
		nTokens = aiConfig.maxVisibleTokens
	
			# Finally, create the receptive field (which actually just means, 
			# the GLaDOS system's input interface to the core AI's real receptive 
			# field), passing it the nTokens parameter to tell it how big it is.
		
		_logger.info("Cognitive system:  Creating {nTokens}-token receptive field...")
		TheReceptiveField(nTokens)
		
		#|--------------------------------------
		#| Step 2:  Create our cognitive stream.
		
		## Not implemented yet.
		
		#|---------------------------------------
		#| Step 3:  Subscribe to notifications.
		
		#|---------------------------------------
		#| Step 4:  Create our cognitive process.
		
		## Not implemented yet.
	
	#__/ End singleton instance initializer theCognitiveSystem.__init__().

	def inputChannels():
		"""
			Returns a list of input channels that we would like to have filled 
			with information generated by the system.  Presently, this consists
			of a single action channel, to which the action subsystem should 
			deliver all actions created/initiated/executed/completed thoughout
			GLaDOS. At present, this channel filters this data to a limited 
			subset of interesting actions which are broadcast within the AI's 
			cognitive sphere, resulted in them being added to the AI's cognitive
			stream, and thereafter becoming able to be viewed in its receptive
			field.
		"""
		return [The_AI_Cognosphere_Channel()]

#__/ End singleton class TheCognitiveSystem.


#|^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
#|					   END OF FILE:	  mind/mindSystem.py
#|%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%